---
tags:
  - math_220
created: 2024-11-19
---

> *Theorem: The Gram-Schmidt Process*
> Given a [[Linearly Independent Basis|basis]] $\{ \vec x_1, \dots, \vec x_p \}$ for a nonzero subspace $W$ of $\mathbb R^n$, define
> $\vec v_1 = \vec x_1$
> $\vec v_2 = \vec x_2 - \dfrac{\vec x_2 \cdot \vec v_1}{\vec v_1 \cdot \vec v_1} \vec v_1$
> $\vec v_3 = \vec x_3 - \dfrac{\vec x_3 \cdot \vec v_1}{\vec v_1 \cdot \vec v_1} \vec v_1 - \dfrac{\vec x_3 \cdot \vec v_2}{\vec v_2 \cdot \vec v_2} \vec v_2$
> $\vdots$
> $\vec v_p = \vec x_p - \dfrac{\vec x_p \cdot \vec v_1}{\vec v_1 \cdot \vec v_1} \vec v_1 - \dfrac{\vec x_p \cdot \vec v_2}{\vec v_2 \cdot \vec v_2} \vec v_2 - \cdots - \dfrac{\vec x_p \cdot \vec v_{p - 1}}{\vec v_{p - 1} \cdot \vec v_{p - 1}} \vec v_{p - 1}$.
> Then $\{ \vec v_1, \dots, \vec v_p \}$ is an [[6.2 Orthogonal Sets|orthogonal basis]] for $W$. In addition,
> $$ \text{Span}\{ \vec v_1, \dots, \vec v_k \} = \text{Span}\{ \vec x_1, \dots, \vec x_k \} \quad \text{for } 1 \leq k \leq p. $$

> *Theorem: The QR Factorisation*
> If $A$ is an $m \times n$ matrix with [[1.7 Linear Independence|linearly independent]] columns, then $A$ can be factored as $A = QR$, where $Q$ is an $m \times n$ matrix whose columns form an orthonormal basis for $\text{Col}A$ and $R$ is an $n \times n$ upper triangular [[2.2 Inverses|invertible]] matrix with positive entries on its diagonal.