---
tags:
  - math_220
created: 2024-09-26
---

Matrices are typically defined by capital letters (e.g. the matrix $A$).
Matrix entries are typically defined by lowercase letters with subscripts $i, j$ representing the rows and columns respectively (e.g. $a_{12}$).

The **main diagonal** of a matrix will be given as all entries of the form $a_{i, i}$ for all defined $i$. A diagonal matrix is a square $n \times n$ matrix whose non-diagonal entries are zero. The identity matrix, $I_n$, is a diagonal matrix where each entry on the main diagonal is $1$.

Note: Two matrices are considered equal if they have the same size and have the same entries.

## Matrix Addition

We use the analogue of vector addition to define matrix addition. That is to say, we add matrices $A$ and $B$ by adding the entries $a_{i, j}$ and $b_{i, j}$ for all $i$ and $j$.

> *Example*
> $\begin{bmatrix} 2 & 3 \\ -1 & 1 \\ 0 & 1 \end{bmatrix} + \begin{bmatrix} -2 & -1 \\ 1 & 0 \\ 2 & 3 \end{bmatrix}$

$= \begin{bmatrix} 0 & 2 \\ 0 & 1 \\ 2 & 4 \end{bmatrix}$

## Matrix Scalar Multiplication

Again, we will create an analogous definition to multiplying a vector by a scalar. For a matrix $A$ and scalar $c$, $cA$ is defined by multiplying each entry in $A$ by $c$.

> *Example*
> $3 \begin{bmatrix} 2 & 3 \\ 0 & -1 \\ -2 & 0 \end{bmatrix}$

$= \begin{bmatrix} 6 & 9 \\ 0 & -3 \\ -6 & 0 \end{bmatrix}$

> *Theorem*
> Let $A$, $B$, and $C$ be matrices of the same size, and let $r$ and $s$ be scalars.
> 1. $A + B = B + A$
> 2. $(A + B) + C = A + (B + C)$
> 3. $A + 0 = A$
> 4. $r(A + B) = rA + rB$
> 5. $(r + s)A = rA + sA$
> 6. $r(sA) = (rs)A$

## Matrix Multiplication

> *Definition: Matrix Multiplication*
> If $A$ is an $m \times n$ matrix, and if $B$ is an $n \times p$ matrix with columns $b_1, \dots, b_p$, then the product $AB$ is the $m \times p$ matrix whose columns are $Ab_1, \dots, A B_p$. That is,
> $$ AB = A \begin{bmatrix} b_1 & b_2 & \dots & b_p \end{bmatrix} = \begin{bmatrix} A b_1 & A b_2 & \dots & A b_p \end{bmatrix}. $$

> *Definition: Row-Column Rule for Computing AB*
> If the product $AB$ is defined, then the entry in row $i$ and column $j$ of $AB$ is the sum of the products of corresponding entries from row $i$ of $A$ and column $j$ of $B$. If $(AB)_{ij}$ denotes the $(i, j)$-entry in $AB$, and if $A$ is an $m \times n$ matrix, then
> $$ (AB)_{ij} = a_{i_1} b_{1_j} + a_{i_2} b_{2_j} + \dots + a_{i_n} b_{n_j}. $$

> *Example*
> Let $A = \begin{bmatrix} 1 & 2 \\ 3 & 1 \end{bmatrix}$ and $B = \begin{bmatrix} 3 & 2 & 1 \\ 0 & -2 & 3 \end{bmatrix}$. Find $AB$ and $BA$.

$AB = \begin{bmatrix} 1 \cdot 3 + 2 \cdot 0 & 1 \cdot 2 + 2 \cdot -2 & 1 \cdot 1 + 2 \cdot 3 \\ 3 \cdot 3 + 1 \cdot 0 & 3 \cdot 2 + 1 \cdot -2 & 3 \cdot 1 + 1 \cdot 3 \end{bmatrix}$

$= \begin{bmatrix} 3 & -2 & 7 \\ 9 & 4 & 6 \end{bmatrix}$

---

Some other notes:
- $AB = BC$ does not imply $B = C$.
- $AB = 0$ does not imply $A = 0$ or $B = 0$.

## Powers of a Matrix

> *Definition: Powers of a Matrix*
> If $A$ is an $n \times n$ matrix and if $k$ is a positive integer, then $A^k$ denotes the product of $k$ copies of $A$:
> $$ A^k = A \cdots A. $$

Note: $A^0 = I_n$.

> *Theorem*
> Let $A$ be an $m \times n$ matrix, and let $B$ and $C$ have sizes for which the indicated sums and products are defined.
> 1. $A(BC) = (AB)C$
> 2. $A(B + C) = AB + AC$
> 3. $(B + C)A = BA + CA$
> 4. $r(AB) = (rA)B = A(rB)$
> 5. $I_m A = A = A I_n$

## The Transpose of a Matrix

> *Definition: The Transpose of a Matrix*
> Given an $m \times n$ matrix $A$, the transpose of $A$ is the $n \times n$ matrix $A^T$, whose columns are formed from the corresponding rows of $A$.

> *Theorem*
> Let $A$ and $B$ denote matrices whose sizes are appropriate for the following sums and products.
> 1. $(A^T)^T = A$
> 2. $(A + B)^T = A^T + B^T$
> 3. For any scalar $r$, $(rA)^T = rA^T$
> 4. $(AB)^T = B^T A^T$